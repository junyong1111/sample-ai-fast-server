"""
ì˜¤í”„ì²´ì¸ ë¶„ì„ ì„œë¹„ìŠ¤ V2
- ë‰´ìŠ¤, ì†Œì…œë¯¸ë””ì–´, ê±°ì‹œê²½ì œ ì§€í‘œë¥¼ í†µí•© ë¶„ì„
- PRD ê¸°ì¤€ ê°€ì¤‘ì¹˜ ì ìš© (ë‰´ìŠ¤ 40%, ì†Œì…œ 35%, ê±°ì‹œê²½ì œ 25%)
"""

import asyncio
import aiohttp
import json
import os
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import numpy as np

from src.common.utils.offchain_indicators_v2 import (
    OffchainIndicatorsV2, NewsItem, SocialSentiment, MacroIndicator
)
from src.common.utils.social_data_sources import SocialDataAggregator
from src.common.utils.logger import set_logger
from .models import OffchainRequest, OffchainResponse

logger = set_logger("offchain_service_v2")

class OffchainServiceV2:
    """ì˜¤í”„ì²´ì¸ ë¶„ì„ ì„œë¹„ìŠ¤ V2"""

    def __init__(self):
        self.offchain_analyzer = OffchainIndicatorsV2()
        self.session = None

        # ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
        reddit_config: Optional[Dict[str, str]] = None
        twitter_config: Optional[Dict[str, str]] = None

        # Reddit API ì„¤ì •
        reddit_client_id = os.getenv('REDDIT_CLIENT_ID')
        reddit_client_secret = os.getenv('REDDIT_CLIENT_SECRET')
        reddit_user_agent = os.getenv('REDDIT_USER_AGENT', 'QuantumInsight/1.0 by YourUsername')

        if reddit_client_id and reddit_client_secret:
            reddit_config = {
                'client_id': reddit_client_id,
                'client_secret': reddit_client_secret,
                'user_agent': reddit_user_agent
            }
            logger.info("âœ… Reddit API ì„¤ì • ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ Reddit API ì„¤ì • ì—†ìŒ - í™˜ê²½ë³€ìˆ˜ í™•ì¸ í•„ìš”")

        # Twitter API ì„¤ì •
        twitter_bearer_token = os.getenv('TWITTER_BEARER_TOKEN')

        if twitter_bearer_token:
            twitter_config = {
                'bearer_token': twitter_bearer_token
            }
            logger.info("âœ… Twitter API ì„¤ì • ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ Twitter API ì„¤ì • ì—†ìŒ - í™˜ê²½ë³€ìˆ˜ í™•ì¸ í•„ìš”")

        self.social_aggregator = SocialDataAggregator(
            reddit_config=reddit_config,
            twitter_config=twitter_config
        )

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def analyze_offchain_sentiment(
        self,
        market: str = "BTC/USDT",
        timeframe: str = "minutes:60",
        count: int = 200
    ) -> Dict[str, Any]:
        """ì˜¤í”„ì²´ì¸ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„"""
        try:
            logger.info("ğŸš€ [2ë‹¨ê³„] ì˜¤í”„ì²´ì¸ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹œì‘")
            logger.info(f"ğŸ“Š {market} | {timeframe} | {count}ê°œ ìº”ë“¤")

            # 1. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            try:
                news_items = await self._collect_news_data()
                logger.info(f"âœ… ë‰´ìŠ¤ ë°ì´í„°: {len(news_items)}ê°œ")
            except Exception as e:
                logger.warning(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                news_items = []

            # 2. ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘
            try:
                social_data = await self._collect_social_data()
                logger.info(f"âœ… ì†Œì…œë¯¸ë””ì–´ ë°ì´í„°: {len(social_data)}ê°œ")
            except Exception as e:
                logger.warning(f"ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                social_data = []

            # 3. ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘
            try:
                macro_data = await self._collect_macro_data()
                logger.info(f"âœ… ê±°ì‹œê²½ì œ ë°ì´í„°: {len(macro_data)}ê°œ")
            except Exception as e:
                logger.warning(f"ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                macro_data = []

            # 4. í†µí•© ë¶„ì„
            try:
                analysis_result = await self.offchain_analyzer.analyze_offchain_sentiment(
                    news_items, social_data, macro_data
                )
            except Exception as e:
                logger.error(f"í†µí•© ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„±
                analysis_result = {
                    "offchain_score": 0.0,
                    "signal": "HOLD",
                    "signal_description": "ğŸŸ¡ ë¶„ì„ ì‹¤íŒ¨",
                    "confidence": 0.0,
                    "news_analysis": {"analysis": "ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨", "news_count": 0},
                    "social_analysis": {"analysis": "ì†Œì…œ ë¶„ì„ ì‹¤íŒ¨", "platform_count": 0, "total_mentions": 0},
                    "macro_analysis": {"analysis": "ê±°ì‹œê²½ì œ ë¶„ì„ ì‹¤íŒ¨", "indicator_count": 0},
                    "weights": {"news": 0.4, "social": 0.35, "macro": 0.25}
                }

            # 5. ê²°ê³¼ êµ¬ì¡°í™”
            try:
                result = self._structure_analysis_result(
                    market, timeframe, analysis_result
                )
            except Exception as e:
                logger.error(f"ê²°ê³¼ êµ¬ì¡°í™” ì‹¤íŒ¨: {str(e)}")
                result = self._create_error_response(market, timeframe, str(e))

            logger.info("ğŸ‰ [2ë‹¨ê³„] ì˜¤í”„ì²´ì¸ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì™„ë£Œ!")
            logger.info(f"ğŸ“Š ê²°ê³¼: {analysis_result['signal_description']} | ì ìˆ˜: {analysis_result['offchain_score']:.3f}")

            return result

        except Exception as e:
            logger.error(f"ì˜¤í”„ì²´ì¸ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return self._create_error_response(market, timeframe, str(e))

    async def _collect_news_data(self) -> List[NewsItem]:
        """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (ëª¨ì˜ ë°ì´í„°)"""
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” NewsAPI, GDELT, RSS í”¼ë“œ ë“±ì„ ì‚¬ìš©
            # í˜„ì¬ëŠ” ëª¨ì˜ ë°ì´í„°ë¡œ êµ¬í˜„

            mock_news = [
                NewsItem(
                    title="Bitcoin ETF Approval Expected This Week",
                    source="Reuters",
                    published_at=datetime.now() - timedelta(hours=2),
                    sentiment_score=0.7,
                    relevance_score=0.9,
                    url="https://reuters.com/bitcoin-etf"
                ),
                NewsItem(
                    title="Crypto Regulation Concerns Rise in Europe",
                    source="Bloomberg",
                    published_at=datetime.now() - timedelta(hours=4),
                    sentiment_score=-0.3,
                    relevance_score=0.8,
                    url="https://bloomberg.com/crypto-regulation"
                ),
                NewsItem(
                    title="Major Bank Announces Bitcoin Custody Services",
                    source="WSJ",
                    published_at=datetime.now() - timedelta(hours=6),
                    sentiment_score=0.5,
                    relevance_score=0.7,
                    url="https://wsj.com/bitcoin-custody"
                ),
                NewsItem(
                    title="Bitcoin Mining Difficulty Reaches New High",
                    source="CoinDesk",
                    published_at=datetime.now() - timedelta(hours=8),
                    sentiment_score=0.2,
                    relevance_score=0.6,
                    url="https://coindesk.com/mining-difficulty"
                )
            ]

            return mock_news

        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []

    async def _collect_social_data(self) -> List[SocialSentiment]:
        """ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì œ Reddit & Twitter API)"""
        try:
            # ì‹¤ì œ Redditê³¼ Twitter APIë¥¼ í†µí•œ ë°ì´í„° ìˆ˜ì§‘
            social_mentions = await self.social_aggregator.collect_social_mentions(
                reddit_limit=50,
                twitter_limit=50,
                hours_back=24
            )

            # SocialSentiment í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            social_data = []

            # í”Œë«í¼ë³„ë¡œ ê·¸ë£¹í™”
            reddit_mentions = [m for m in social_mentions if m.platform == 'reddit']
            twitter_mentions = [m for m in social_mentions if m.platform == 'twitter']

            # Reddit ë°ì´í„° ì²˜ë¦¬
            if reddit_mentions:
                try:
                    reddit_analysis = self.social_aggregator.calculate_platform_sentiment(reddit_mentions, 'reddit')
                    social_data.append(SocialSentiment(
                        platform="reddit",
                        mention_count=reddit_analysis['mention_count'],
                        sentiment_score=reddit_analysis['sentiment_score'],
                        trend_score=reddit_analysis['trend_score'],
                        timestamp=datetime.now() - timedelta(hours=1)
                    ))
                except Exception as e:
                    logger.warning(f"Reddit ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

            # Twitter ë°ì´í„° ì²˜ë¦¬
            if twitter_mentions:
                try:
                    twitter_analysis = self.social_aggregator.calculate_platform_sentiment(twitter_mentions, 'twitter')
                    social_data.append(SocialSentiment(
                        platform="twitter",
                        mention_count=twitter_analysis['mention_count'],
                        sentiment_score=twitter_analysis['sentiment_score'],
                        trend_score=twitter_analysis['trend_score'],
                        timestamp=datetime.now() - timedelta(hours=1)
                    ))
                except Exception as e:
                    logger.warning(f"Twitter ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

            # API ì‹¤íŒ¨ ì‹œ ëª¨ì˜ ë°ì´í„° ì‚¬ìš©
            if not social_data:
                logger.warning("ì†Œì…œë¯¸ë””ì–´ API ì‹¤íŒ¨, ëª¨ì˜ ë°ì´í„° ì‚¬ìš©")
                social_data = [
                    SocialSentiment(
                        platform="reddit",
                        mention_count=890,
                        sentiment_score=0.2,
                        trend_score=0.4,
                        timestamp=datetime.now() - timedelta(hours=2)
                    ),
                    SocialSentiment(
                        platform="twitter",
                        mention_count=1250,
                        sentiment_score=0.4,
                        trend_score=0.6,
                        timestamp=datetime.now() - timedelta(hours=1)
                    )
                ]

            return social_data

        except Exception as e:
            logger.error(f"ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            # ì—ëŸ¬ ì‹œ ëª¨ì˜ ë°ì´í„° ë°˜í™˜
            return [
                SocialSentiment(
                    platform="reddit",
                    mention_count=890,
                    sentiment_score=0.2,
                    trend_score=0.4,
                    timestamp=datetime.now() - timedelta(hours=2)
                ),
                SocialSentiment(
                    platform="twitter",
                    mention_count=1250,
                    sentiment_score=0.4,
                    trend_score=0.6,
                    timestamp=datetime.now() - timedelta(hours=1)
                )
            ]

    async def _collect_macro_data(self) -> List[MacroIndicator]:
        """ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘ (ëª¨ì˜ ë°ì´í„°)"""
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” FRED API, Yahoo Finance, Investing.com ë“±ì„ ì‚¬ìš©
            # í˜„ì¬ëŠ” ëª¨ì˜ ë°ì´í„°ë¡œ êµ¬í˜„

            mock_macro = [
                MacroIndicator(
                    indicator="cpi",
                    value=3.2,
                    previous_value=3.1,
                    change_pct=0.1,
                    impact_score=0.2,
                    timestamp=datetime.now() - timedelta(days=1)
                ),
                MacroIndicator(
                    indicator="interest_rate",
                    value=5.25,
                    previous_value=5.0,
                    change_pct=0.25,
                    impact_score=-0.3,
                    timestamp=datetime.now() - timedelta(days=2)
                ),
                MacroIndicator(
                    indicator="dxy",
                    value=103.5,
                    previous_value=104.2,
                    change_pct=-0.7,
                    impact_score=0.1,
                    timestamp=datetime.now() - timedelta(days=3)
                ),
                MacroIndicator(
                    indicator="unemployment",
                    value=3.8,
                    previous_value=3.9,
                    change_pct=-0.1,
                    impact_score=0.1,
                    timestamp=datetime.now() - timedelta(days=4)
                )
            ]

            return mock_macro

        except Exception as e:
            logger.error(f"ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []

    def _structure_analysis_result(
        self,
        market: str,
        timeframe: str,
        analysis_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ êµ¬ì¡°í™”"""
        try:
            # ì¸ê°„ ì¹œí™”ì  ë¶„ì„ ê²°ê³¼
            analysis = {
                "overall_sentiment": {
                    "signal": analysis_result['signal_description'],
                    "score": f"{analysis_result['offchain_score']:.3f}",
                    "confidence": f"{analysis_result['confidence']:.1%}",
                    "interpretation": self._get_sentiment_interpretation(analysis_result['offchain_score'])
                },
                "news_analysis": {
                    "sentiment": analysis_result['news_analysis']['analysis'],
                    "news_count": analysis_result['news_analysis']['news_count'],
                    "positive_news": analysis_result['news_analysis']['positive_news'],
                    "negative_news": analysis_result['news_analysis']['negative_news'],
                    "neutral_news": analysis_result['news_analysis']['neutral_news']
                },
                "social_analysis": {
                    "sentiment": analysis_result['social_analysis']['analysis'],
                    "platform_count": analysis_result['social_analysis']['platform_count'],
                    "total_mentions": analysis_result['social_analysis']['total_mentions'],
                    "trend_score": f"{analysis_result['social_analysis']['trend_score']:.2f}"
                },
                "macro_analysis": {
                    "impact": analysis_result['macro_analysis']['analysis'],
                    "indicator_count": analysis_result['macro_analysis']['indicator_count'],
                    "overall_impact": f"{analysis_result['macro_analysis']['overall_impact']:.3f}"
                },
                "weight_distribution": {
                    "news_weight": f"{analysis_result['weights']['news']:.0%}",
                    "social_weight": f"{analysis_result['weights']['social']:.0%}",
                    "macro_weight": f"{analysis_result['weights']['macro']:.0%}"
                }
            }

            # ìƒì„¸ ë°ì´í„° (AI/ì‹œìŠ¤í…œìš©)
            detailed_data = {
                "offchain_score": analysis_result['offchain_score'],
                "signal": analysis_result['signal'],
                "confidence": analysis_result['confidence'],
                "news_analysis": analysis_result['news_analysis'],
                "social_analysis": analysis_result['social_analysis'],
                "macro_analysis": analysis_result['macro_analysis'],
                "weights": analysis_result['weights']
            }

            return {
                "status": "success",
                "market": market,
                "timeframe": timeframe,
                "timestamp": datetime.now().isoformat(),
                "analysis": analysis,
                "detailed_data": detailed_data,
                "metadata": {
                    "data_sources": ["news", "social", "macro"],
                    "analysis_type": "offchain_sentiment",
                    "version": "v2"
                }
            }

        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ êµ¬ì¡°í™” ì‹¤íŒ¨: {str(e)}")
            return self._create_error_response(market, timeframe, str(e))

    def _get_sentiment_interpretation(self, score: float) -> str:
        """ì„¼í‹°ë©˜íŠ¸ ì ìˆ˜ í•´ì„"""
        if score >= 0.6:
            return "ë§¤ìš° ê°•í•œ ê¸ì •ì  ì‹ í˜¸"
        elif score >= 0.3:
            return "ê°•í•œ ê¸ì •ì  ì‹ í˜¸"
        elif score >= 0.1:
            return "ì•½í•œ ê¸ì •ì  ì‹ í˜¸"
        elif score >= -0.1:
            return "ì¤‘ë¦½ì  ì‹ í˜¸"
        elif score >= -0.3:
            return "ì•½í•œ ë¶€ì •ì  ì‹ í˜¸"
        elif score >= -0.6:
            return "ê°•í•œ ë¶€ì •ì  ì‹ í˜¸"
        else:
            return "ë§¤ìš° ê°•í•œ ë¶€ì •ì  ì‹ í˜¸"

    def _create_error_response(self, market: str, timeframe: str, error_msg: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            "status": "error",
            "market": market,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "error": error_msg,
            "analysis": {
                "overall_sentiment": {
                    "signal": "ğŸŸ¡ ë¶„ì„ ì‹¤íŒ¨",
                    "score": "0.000",
                    "confidence": "0.0%",
                    "interpretation": "ë°ì´í„° ìˆ˜ì§‘ ë˜ëŠ” ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
                }
            },
            "detailed_data": {
                "offchain_score": 0.0,
                "signal": "HOLD",
                "confidence": 0.0
            },
            "metadata": {
                "error": True,
                "error_message": error_msg
            }
        }
