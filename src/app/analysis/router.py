"""
ë¶„ì„ ì¡°íšŒ API ë¼ìš°í„° (ì°¨íŠ¸, ë¦¬ìŠ¤í¬, ì†Œì…œ)
"""
from typing import List
from fastapi import APIRouter, HTTPException, Query
import asyncpg
from src.config.database import database_config
from datetime import datetime, timedelta, timezone
import json

from src.common.utils.logger import set_logger
from src.app.analysis.service import AnalysisService

logger = set_logger(__name__)
router = APIRouter(tags=["Analysis"])

@router.get(
    "/chart",
    summary="ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ",
    description="íŠ¹ì • í‹°ì»¤ ëª©ë¡ê³¼ ì‹œê°„ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
)
async def get_chart_analysis(
    tickers: str = Query("BTC/USDT,ETH/USDT", description="ì¡°íšŒí•  í‹°ì»¤ ëª©ë¡ (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: BTC/USDT,ETH/USDT)"),
    hours_back: int = Query(24, ge=1, le=720, description="ëª‡ ì‹œê°„ ì „ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí• ì§€ (ìµœëŒ€ 720ì‹œê°„ = 30ì¼)"),
    limit: int = Query(100, ge=1, le=1000, description="ê° í‹°ì»¤ë³„ë¡œ ì¡°íšŒí•  ìµœëŒ€ ê²°ê³¼ ìˆ˜")
):
    """
    íŠ¹ì • í‹°ì»¤ ëª©ë¡ê³¼ ì‹œê°„ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        tickers: ì¡°íšŒí•  í‹°ì»¤ ëª©ë¡ (ì½¤ë§ˆë¡œ êµ¬ë¶„)
        hours_back: ëª‡ ì‹œê°„ ì „ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí• ì§€
        limit: ê° í‹°ì»¤ë³„ë¡œ ì¡°íšŒí•  ìµœëŒ€ ê²°ê³¼ ìˆ˜

    Returns:
        í•´ë‹¹ í‹°ì»¤ë“¤ì˜ ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    try:
        # ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ í‹°ì»¤ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        ticker_list = [ticker.strip() for ticker in tickers.split(',') if ticker.strip()]

        if not ticker_list:
            raise HTTPException(status_code=400, detail="í‹°ì»¤ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        logger.info(f"ğŸ“Š ì°¨íŠ¸ ë¶„ì„ ì¡°íšŒ ìš”ì²­: {len(ticker_list)}ê°œ í‹°ì»¤, {hours_back}ì‹œê°„ ì „ë¶€í„°")

        service = AnalysisService()
        reports = await service.get_chart_analysis_by_tickers(ticker_list, hours_back, limit)

        return {
            "status": "success",
            "data": reports,
            "message": f"ìš”ì²­ëœ í‹°ì»¤ ë° ì‹œê°„ ë²”ìœ„ì— ëŒ€í•œ ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.",
            "query": {
                "tickers": ticker_list,
                "hours_back": hours_back,
                "limit": limit
            }
        }
    except Exception as e:
        logger.error(f"âŒ ì°¨íŠ¸ ë¶„ì„ ì¡°íšŒ API ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì°¨íŠ¸ ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@router.get(
    "/risk",
    summary="ë¦¬ìŠ¤í¬ ë¶„ì„ ì¡°íšŒ",
    description="ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ ë¯¸ë¦¬ ë¶„ì„í•œ ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
)
async def get_risk_analysis(
    market: str = Query(..., description="ì¡°íšŒí•  ë§ˆì¼“ (ì˜ˆ: BTC/USDT)"),
    hours_back: int = Query(24, ge=1, le=168, description="ëª‡ ì‹œê°„ ì „ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí• ì§€ (ìµœëŒ€ 168ì‹œê°„ = 7ì¼)"),
    limit: int = Query(10, ge=1, le=100, description="ì¡°íšŒí•  ìµœëŒ€ ê²°ê³¼ ìˆ˜")
):
    """
    ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (GET ë°©ì‹)

    ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ 1ì‹œê°„ë§ˆë‹¤ ë¯¸ë¦¬ ë¶„ì„í•œ ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        conn = await asyncpg.connect(
            host=database_config.POSTGRESQL_DB_HOST,
            port=int(database_config.POSTGRESQL_DB_PORT),
            database=database_config.POSTGRESQL_DB_DATABASE,
            user=database_config.POSTGRESQL_DB_USER,
            password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
            now_utc = datetime.now(timezone.utc)
            start_time_naive = now_utc.replace(tzinfo=None) - timedelta(hours=hours_back)
            start_time = start_time_naive

            # ìµœì‹  ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
            query = """
                SELECT
                    asset_symbol,
                    risk_score,
                    market_risk_level,
                    risk_off_signal,
                    confidence,
                    risk_indicators,
                    correlation_analysis,
                    full_analysis_data,
                    created_at,
                    expires_at
                FROM risk_analysis_reports
                WHERE asset_symbol = $1
                AND created_at >= $2::timestamp
                ORDER BY created_at DESC
                LIMIT $3
            """

            rows = await conn.fetch(query, market, start_time, limit)

            if not rows:
                return {
                    "status": "success",
                    "market": market,
                    "message": "í•´ë‹¹ ë§ˆì¼“ì— ëŒ€í•œ ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "data": [],
                    "query_info": {
                        "market": market,
                        "hours_back": hours_back,
                        "limit": limit,
                        "queried_at": datetime.now().isoformat()
                    }
                }

            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            results = []
            for row in rows:
                result_dict = dict(row)
                results.append(result_dict)

            # ê°€ì¥ ìµœì‹  ê²°ê³¼ë¥¼ ë©”ì¸ ì‘ë‹µìœ¼ë¡œ ì‚¬ìš©
            latest_result = results[0]

            return {
                "status": "success",
                "market": market,
                "timestamp": latest_result['created_at'].isoformat(),
                "risk_grade": latest_result['market_risk_level'],
                "analysis": {
                    "risk_indicators": latest_result['risk_indicators'],
                    "correlation_analysis": latest_result['correlation_analysis'],
                    "risk_off_signal": latest_result['risk_off_signal'],
                    "confidence": latest_result['confidence']
                },
                "metadata": {
                    "analysis_period": f"{hours_back}ì‹œê°„",
                    "data_points": len(results),
                    "latest_analysis_at": latest_result['created_at'].isoformat(),
                    "expires_at": latest_result['expires_at'].isoformat()
                },
                "historical_data": results
            }

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"âŒ ë¦¬ìŠ¤í¬ ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ë¦¬ìŠ¤í¬ ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )