"""
ê°„ë‹¨í•œ ì°¨íŠ¸ ë¶„ì„ Celery íƒœìŠ¤í¬
"""
import asyncio
import json
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, List

from celery import Celery
from src.scheduler.celery import app as celery_app
from src.common.utils.logger import set_logger
from src.app.autotrading_v2.quantitative_service import QuantitativeServiceV2
from src.app.analysis.ai_service import AIAnalysisService

logger = set_logger(__name__)

def get_top_20_coins() -> List[str]:
    """
    ccxtë¥¼ í†µí•´ ìƒìœ„ 20ê°œ ì½”ì¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Returns:
        List[str]: ìƒìœ„ 20ê°œ ì½”ì¸ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ (USDT í˜ì–´)
    """
    try:
        import ccxt

        # Binance ê±°ë˜ì†Œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        exchange = ccxt.binance({
            'apiKey': '',  # ê³µê°œ APIë§Œ ì‚¬ìš©
            'secret': '',
            'sandbox': False,
            'enableRateLimit': True,
        })

        # ëª¨ë“  ê±°ë˜ ê°€ëŠ¥í•œ ì‹¬ë³¼ ê°€ì ¸ì˜¤ê¸°
        markets = exchange.load_markets()

        # USDT í˜ì–´ë§Œ í•„í„°ë§í•˜ê³  ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        usdt_pairs = []
        for symbol, market in markets.items():
            if (market['quote'] == 'USDT' and
                market['active'] and
                market['type'] == 'spot' and
                market['base'] not in ['USDT', 'USDC', 'DAI', 'BUSD']):  # ìŠ¤í…Œì´ë¸”ì½”ì¸ ì œì™¸
                usdt_pairs.append(symbol)

        # ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (24ì‹œê°„ ê±°ë˜ëŸ‰)
        try:
            tickers = exchange.fetch_tickers(usdt_pairs)
            sorted_pairs = sorted(
                usdt_pairs,
                key=lambda x: tickers[x]['quoteVolume'] if x in tickers else 0,
                reverse=True
            )
            top_20 = sorted_pairs[:20]
        except:
            # ê±°ë˜ëŸ‰ ì •ë ¬ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìˆœì„œë¡œ ìƒìœ„ 20ê°œ
            top_20 = usdt_pairs[:20]

        logger.info(f"âœ… ccxtë¥¼ í†µí•œ ìƒìœ„ 20ê°œ ì½”ì¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {len(top_20)}ê°œ")
        logger.info(f"ğŸ“‹ ìƒìœ„ 5ê°œ ì½”ì¸: {', '.join(top_20[:5])}")
        return top_20

    except Exception as e:
        logger.error(f"âŒ ccxtë¥¼ í†µí•œ ìƒìœ„ 20ê°œ ì½”ì¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return get_fallback_coins()

def get_fallback_coins() -> List[str]:
    """
    API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ì½”ì¸ ëª©ë¡

    Returns:
        List[str]: ê¸°ë³¸ ì½”ì¸ ëª©ë¡
    """
    return [
        "BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "SOL/USDT",
        "ADA/USDT", "DOGE/USDT", "TRX/USDT", "AVAX/USDT", "LINK/USDT",
        "DOT/USDT", "MATIC/USDT", "LTC/USDT", "BCH/USDT", "UNI/USDT",
        "ATOM/USDT", "FIL/USDT", "XLM/USDT", "VET/USDT", "ICP/USDT"
    ]

async def save_to_database(market: str, analysis_data: Dict[str, Any], task_id: str) -> bool:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (asyncpg ì‚¬ìš©)

    Args:
        market: ë§ˆì¼“ ì‹¬ë³¼
        analysis_data: ë¶„ì„ ë°ì´í„°
        task_id: íƒœìŠ¤í¬ ID

    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        import asyncpg
        from src.config.database import database_config

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        conn = await asyncpg.connect(
            host=database_config.POSTGRESQL_DB_HOST,
            port=int(database_config.POSTGRESQL_DB_PORT),
            database=database_config.POSTGRESQL_DB_DATABASE,
            user=database_config.POSTGRESQL_DB_USER,
            password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            # ë§Œë£Œ ì‹œê°„ ì„¤ì • (5ë¶„ í›„)
            expires_at = datetime.now(timezone.utc) + timedelta(minutes=5)

            query = """
                INSERT INTO chart_analysis_reports (
                    asset_symbol, overall_score, quant_score, market_regime,
                    weight_snapshot, indicator_scores, full_analysis_data, expires_at
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8
                )
                ON CONFLICT (asset_symbol, created_at)
                DO UPDATE SET
                    overall_score = EXCLUDED.overall_score,
                    quant_score = EXCLUDED.quant_score,
                    market_regime = EXCLUDED.market_regime,
                    weight_snapshot = EXCLUDED.weight_snapshot,
                    indicator_scores = EXCLUDED.indicator_scores,
                    full_analysis_data = EXCLUDED.full_analysis_data,
                    expires_at = EXCLUDED.expires_at
            """

            # ê°€ì¤‘ì¹˜ ìŠ¤ëƒ…ìƒ· ìƒì„±
            weight_snapshot = {
                "regime_type": analysis_data.get('market_regime', 'unknown'),
                "regime_confidence": analysis_data.get('regime_confidence', 0.0),
                "adx_value": analysis_data.get('adx_value', 0.0),
                "analysis_timestamp": analysis_data.get('timestamp', datetime.now(timezone.utc).isoformat())
            }

            # ì§€í‘œ ì ìˆ˜ë“¤
            indicator_scores = {
                "rsi": analysis_data.get('rsi_value', 0.0),
                "macd": analysis_data.get('macd_value', 0.0),
                "adx": analysis_data.get('adx_value', 0.0)
            }

            await conn.execute(
                query,
                market,
                analysis_data.get('overall_score', 0.0),
                analysis_data.get('overall_score', 0.0),  # quant_scoreëŠ” overall_scoreì™€ ë™ì¼
                analysis_data.get('market_regime', 'unknown'),
                json.dumps(weight_snapshot),
                json.dumps(indicator_scores),
                json.dumps(analysis_data),
                expires_at
            )

            return True

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"âŒ [DB-{task_id}] ì €ì¥ ì‹¤íŒ¨: {market} - {str(e)}")
        return False

@celery_app.task(bind=True, name='scheduler.tasks.chart_analysis.analyze_top_20_coins')
def analyze_top_20_coins(self, timeframe: str = "minutes:60", count: int = 200, exchange: str = "binance"):
    """
    ìƒìœ„ 20ê°œ ì½”ì¸ ì°¨íŠ¸ ë¶„ì„ (APIë¥¼ í†µí•œ ë™ì  ì½”ì¸ ëª©ë¡)

    Args:
        timeframe: ì‹œê°„í”„ë ˆì„
        count: ìº”ë“¤ ê°œìˆ˜
        exchange: ê±°ë˜ì†Œ

    Returns:
        Dict[str, Any]: ë¶„ì„ ê²°ê³¼
    """
    task_id = self.request.id
    logger.info(f"ğŸš€ [TOP20-{task_id}] ìƒìœ„ 20ê°œ ì½”ì¸ ì°¨íŠ¸ ë¶„ì„ ì‹œì‘")

    try:
        # QuantitativeServiceV2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        service = QuantitativeServiceV2()

        results = {}
        success_count = 0
        error_count = 0

        # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰ì„ ìœ„í•œ ë£¨í”„ ìƒì„±
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            # ccxtë¥¼ í†µí•´ ìƒìœ„ 20ê°œ ì½”ì¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            top_coins = get_top_20_coins()
            logger.info(f"ğŸ“Š [TOP20-{task_id}] ë¶„ì„ ëŒ€ìƒ ì½”ì¸: {len(top_coins)}ê°œ")
            logger.info(f"ğŸ“‹ [TOP20-{task_id}] ì½”ì¸ ëª©ë¡: {', '.join(top_coins[:5])}...")

            # ê° ì½”ì¸ë³„ë¡œ ë¶„ì„ (ë¹„ë™ê¸° ë£¨í”„)
            for i, market in enumerate(top_coins):
                try:
                    logger.info(f"ğŸ“Š [TOP20-{task_id}] ë¶„ì„ ì¤‘: {market} ({i+1}/{len(top_coins)})")

                    # ì°¨íŠ¸ ë¶„ì„ ì‹¤í–‰ (ë¹„ë™ê¸°)
                    result = loop.run_until_complete(service.analyze_market(
                        market=market,
                        timeframe=timeframe,
                        count=count,
                        exchange=exchange
                    ))

                    if result and result.get('status') == 'success':
                        # ê°„ë‹¨í•œ ë°ì´í„° ì¶”ì¶œ
                        detailed_data = result.get('detailed_data', {})

                        # í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
                        simple_result = {
                            'market': market,
                            'overall_score': detailed_data.get('weighted_score', 0.0),
                            'market_regime': detailed_data.get('regime', 'unknown'),
                            'regime_confidence': detailed_data.get('regime_confidence', 0.0),
                            'adx_value': detailed_data.get('indicators', {}).get('adx', 0.0),
                            'rsi_value': detailed_data.get('indicators', {}).get('rsi', 0.0),
                            'macd_value': detailed_data.get('indicators', {}).get('macd', 0.0),
                            'timestamp': datetime.now(timezone.utc).isoformat()
                        }

                        results[market] = simple_result
                        success_count += 1
                        logger.info(f"âœ… [TOP20-{task_id}] ë¶„ì„ ì™„ë£Œ: {market}")

                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                        try:
                            loop.run_until_complete(save_to_database(market, simple_result, task_id))
                            logger.info(f"ğŸ’¾ [TOP20-{task_id}] DB ì €ì¥ ì™„ë£Œ: {market}")
                        except Exception as db_e:
                            logger.error(f"âŒ [TOP20-{task_id}] DB ì €ì¥ ì‹¤íŒ¨: {market} - {str(db_e)}")
                            error_count += 1
                    else:
                        logger.error(f"âŒ [TOP20-{task_id}] ë¶„ì„ ì‹¤íŒ¨: {market}")
                        error_count += 1

                except Exception as e:
                    logger.error(f"âŒ [TOP20-{task_id}] ë¶„ì„ ì—ëŸ¬: {market} - {str(e)}")
                    error_count += 1

        finally:
            loop.close()

        # ê²°ê³¼ ìš”ì•½
        result_summary = {
            'status': 'completed',
            'task_id': task_id,
            'total_markets': len(top_coins),
            'success_count': success_count,
            'error_count': error_count,
            'success_rate': success_count / len(top_coins) if top_coins else 0,
            'results': results,
            'coins_analyzed': top_coins,
            'timestamp': datetime.now(timezone.utc).isoformat()
        }

        logger.info(f"ğŸ¯ [TOP20-{task_id}] ë¶„ì„ ì™„ë£Œ: ì„±ê³µ {success_count}/{len(top_coins)}")
        return result_summary

    except Exception as e:
        logger.error(f"âŒ [TOP20-{task_id}] ì „ì²´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return {
            'status': 'failed',
            'task_id': task_id,
            'error': str(e),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }

@celery_app.task(name='scheduler.tasks.chart_analysis.get_all_analyses')
def get_all_analyses() -> List[Dict[str, Any]]:
    """
    ëª¨ë“  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (asyncpg ì‚¬ìš©)
    """
    try:
        import asyncio
        import asyncpg
        from src.config.database import database_config

        async def _fetch_data():
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            conn = await asyncpg.connect(
                host=database_config.POSTGRESQL_DB_HOST,
                port=int(database_config.POSTGRESQL_DB_PORT),
                database=database_config.POSTGRESQL_DB_DATABASE,
                user=database_config.POSTGRESQL_DB_USER,
                password=database_config.POSTGRESQL_DB_PASSWORD
            )

            try:
                query = """
                    SELECT * FROM chart_analysis_reports
                    WHERE expires_at > NOW()
                    ORDER BY created_at DESC
                """

                rows = await conn.fetch(query)
                results = []

                for row in rows:
                    result_dict = dict(row)
                    results.append(result_dict)

                return results

            finally:
                await conn.close()

        # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(_fetch_data())
        finally:
            loop.close()

    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return []

@celery_app.task(name='scheduler.tasks.chart_analysis.health_check')
def health_check() -> Dict[str, Any]:
    """
    ê°„ë‹¨í•œ í—¬ìŠ¤ ì²´í¬
    """
    return {
        'status': 'healthy',
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'message': 'Simple chart analysis system is running'
    }

@celery_app.task(name="scheduler.tasks.chart_analysis.analyze_top_20_coins_with_ai")
def analyze_top_20_coins_with_ai():
    """
    ìƒìœ„ 20ê°œ ì½”ì¸ì— ëŒ€í•œ AI ì°¨íŠ¸ ë¶„ì„ (1ì‹œê°„ë§ˆë‹¤, ê¸°ì¡´ ë°ì´í„° í™œìš©)
    """
    try:
        logger.info("ğŸ¤– AI ì°¨íŠ¸ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

        # 1. ìµœê·¼ ì°¨íŠ¸ ë¶„ì„ ë°ì´í„° ì¡°íšŒ (ê¸°ì¡´ ë°ì´í„° í™œìš©)
        chart_data = get_recent_chart_analysis_data()

        if not chart_data:
            logger.warning("âš ï¸ ìµœê·¼ ì°¨íŠ¸ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return

        logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ë°ì´í„°: {len(chart_data)}ê°œ")

        # 2. AI ë¶„ì„ìš© ë°ì´í„° êµ¬ì¡° ë³€í™˜
        coins_data = []
        chart_record_ids = []

        for record in chart_data:
            try:
                # ê¸°ì¡´ ì°¨íŠ¸ ë¶„ì„ ë°ì´í„°ë¥¼ AI ë¶„ì„ìš©ìœ¼ë¡œ ë³€í™˜
                coin_data = convert_chart_data_for_ai(record)
                coins_data.append(coin_data)
                chart_record_ids.append(record['id'])
                logger.info(f"âœ… {record['asset_symbol']} ë°ì´í„° ë³€í™˜ ì™„ë£Œ")

            except Exception as e:
                logger.error(f"âŒ {record.get('asset_symbol', 'Unknown')} ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {str(e)}")

        # 3. AI ë¶„ì„ ì‹¤í–‰ (ë‹¤ì¤‘ ì½”ì¸)
        if coins_data:
            # ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                ai_service = AIAnalysisService()
                ai_results = loop.run_until_complete(ai_service.analyze_multiple_coins_with_ai(coins_data))

                # 4. ê°€ì¤‘ì¹˜ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘
                weights_snapshot = loop.run_until_complete(ai_service._get_regime_weights())

                # 5. AI ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•© í…Œì´ë¸”ì— ì €ì¥
                loop.run_until_complete(save_ai_analysis_to_database(
                    ai_results=ai_results,
                    chart_record_ids=chart_record_ids,
                    risk_record_ids=[],
                    social_record_ids=[],
                    total_coins=len(coins_data),
                    weights_snapshot=weights_snapshot
                ))
                logger.info(f"ğŸ‰ AI ì°¨íŠ¸ ë¶„ì„ ì™„ë£Œ: {len(coins_data)}ê°œ ì½”ì¸")
            finally:
                loop.close()
        else:
            logger.warning("âš ï¸ ë³€í™˜ëœ ì°¨íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

    except Exception as e:
        logger.error(f"âŒ AI ì°¨íŠ¸ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤íŒ¨: {str(e)}")
        raise

def get_recent_chart_analysis_data() -> List[Dict[str, Any]]:
    """
    ìµœê·¼ ì°¨íŠ¸ ë¶„ì„ ë°ì´í„° ì¡°íšŒ (AI ë¶„ì„ìš©)
    """
    import asyncio
    import asyncpg
    from src.config.database import database_config
    from datetime import datetime, timedelta, timezone

    async def _get_data():
        conn = await asyncpg.connect(
            host=database_config.POSTGRESQL_DB_HOST,
            port=int(database_config.POSTGRESQL_DB_PORT),
            database=database_config.POSTGRESQL_DB_DATABASE,
            user=database_config.POSTGRESQL_DB_USER,
            password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            # ìµœê·¼ 1ì‹œê°„ ë‚´ì˜ ì°¨íŠ¸ ë¶„ì„ ë°ì´í„° ì¡°íšŒ
            query = """
                SELECT id, asset_symbol, quant_score, overall_score, market_regime, created_at
                FROM chart_analysis_reports
                WHERE created_at >= NOW() - INTERVAL '1 hour'
                ORDER BY created_at DESC
                LIMIT 20
            """

            rows = await conn.fetch(query)
            return [dict(row) for row in rows]

        finally:
            await conn.close()

    # ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(_get_data())
    finally:
        loop.close()

def convert_chart_data_for_ai(record: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê¸°ì¡´ ì°¨íŠ¸ ë¶„ì„ ë°ì´í„°ë¥¼ AI ë¶„ì„ìš©ìœ¼ë¡œ ë³€í™˜
    """
    try:
        # ê¸°ë³¸ ë°ì´í„°ë¡œ AI ë¶„ì„ìš© êµ¬ì¡° ìƒì„±
        return {
            "market": record.get('asset_symbol', 'Unknown'),
            "timeframe": "minutes:60",
            "exchange": "binance",
            "indicators": {
                "adx": 0,  # ê¸°ë³¸ê°’
                "rsi": 0,
                "macd": 0,
                "macd_histogram": 0,
                "bb_pct_b": 0,
                "volume_z_score": 0,
                "ema_20": 0,
                "ema_50": 0,
                "ema_200": 0
            },
            "scores": {
                "rsi": 0,
                "macd": 0,
                "bollinger": 0,
                "volume": 0,
                "momentum": 0
            },
            "regime_info": {
                "regime": record.get('market_regime', 'range'),
                "confidence": 0.5,
                "trend_strength": 'weak'
            },
            "quant_score": record.get('quant_score', 0),
            "overall_score": record.get('overall_score', 0)
        }
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        return {
            "market": record.get('asset_symbol', 'Unknown'),
            "timeframe": "minutes:60",
            "exchange": "binance",
            "indicators": {},
            "scores": {},
            "regime_info": {"regime": "range", "confidence": 0.5, "trend_strength": "weak"},
            "quant_score": 0,
            "overall_score": 0
        }

async def save_ai_analysis_to_database(
    ai_results: Dict[str, Any],
    chart_record_ids: List[int],
    risk_record_ids: List[int],
    social_record_ids: List[int],
    total_coins: int,
    weights_snapshot: Dict[str, Any] = None
):
    """
    AI ì¢…í•© ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    """
    import asyncpg
    from src.config.database import database_config
    from datetime import datetime, timedelta, timezone
    import json

    try:
        conn = await asyncpg.connect(
            host=database_config.POSTGRESQL_DB_HOST,
            port=int(database_config.POSTGRESQL_DB_PORT),
            database=database_config.POSTGRESQL_DB_DATABASE,
            user=database_config.POSTGRESQL_DB_USER,
            password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            analysis_results = ai_results.get('analysis_results', {})
            summary = ai_results.get('summary', {})

            # ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ êµ¬ì„±
            data_sources = {
                "chart_data": {
                    "source_table": "chart_analysis_reports",
                    "record_ids": chart_record_ids,
                    "total_records": len(chart_record_ids),
                    "timeframe": "minutes:60",
                    "exchange": "binance"
                },
                "risk_data": {
                    "source_table": "risk_analysis_reports",
                    "record_ids": risk_record_ids,
                    "total_records": len(risk_record_ids),
                    "analysis_type": "daily"
                },
                "social_data": {
                    "source_table": "social_analysis_reports",
                    "record_ids": social_record_ids,
                    "total_records": len(social_record_ids),
                    "platforms": ["reddit", "twitter"]
                },
                "weights_snapshot": {
                    "source": "information_service",
                    "api_endpoint": "/api/v2/information/weights/chart",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "description": "AI ë¶„ì„ì— ì‚¬ìš©ëœ ë ˆì§ë³„ ê°€ì¤‘ì¹˜ ìŠ¤ëƒ…ìƒ·",
                    "weights_data": weights_snapshot or {}
                }
            }

            # ë§Œë£Œ ì‹œê°„ ì„¤ì • (2ì‹œê°„)
            expires_at = datetime.now(timezone.utc) + timedelta(hours=2)

            query = """
                INSERT INTO ai_analysis_reports
                (analysis_timestamp, chart_analysis, risk_analysis, social_analysis,
                 final_analysis, data_sources, total_coins, expires_at)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
            """

            await conn.execute(
                query,
                datetime.now(timezone.utc),
                json.dumps(analysis_results),  # chart_analysis
                json.dumps({}),  # risk_analysis (ë¹ˆ ê°ì²´)
                json.dumps({}),  # social_analysis (ë¹ˆ ê°ì²´)
                json.dumps({}),  # final_analysis (ë¹ˆ ê°ì²´ - ë³„ë„ ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬)
                json.dumps(data_sources),  # data_sources
                total_coins,
                expires_at
            )

            logger.info(f"âœ… AI ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {total_coins}ê°œ ì½”ì¸")

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"âŒ AI ì¢…í•© ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise

async def save_ai_chart_analysis_to_database(ai_results: Dict[str, Any], total_coins: int):
    """
    AI ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ JSONB í˜•íƒœë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    """
    import asyncpg
    from src.config.database import database_config
    from datetime import datetime, timedelta, timezone
    import json

    try:
        conn = await asyncpg.connect(
            host=database_config.POSTGRESQL_DB_HOST,
            port=int(database_config.POSTGRESQL_DB_PORT),
            database=database_config.POSTGRESQL_DB_DATABASE,
            user=database_config.POSTGRESQL_DB_USER,
            password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            analysis_results = ai_results.get('analysis_results', {})
            summary = ai_results.get('summary', {})

            # í†µê³„ ê³„ì‚°
            trend_coins = summary.get('trend_coins', 0)
            range_coins = summary.get('range_coins', 0)
            average_confidence = summary.get('average_confidence', 0.0)

            # JSONB ë°ì´í„° ì¤€ë¹„
            analysis_data_json = json.dumps(analysis_results)

            # ë§Œë£Œ ì‹œê°„ ì„¤ì • (2ì‹œê°„)
            expires_at = datetime.now(timezone.utc) + timedelta(hours=2)

            query = """
                INSERT INTO ai_chart_analysis_reports
                (analysis_timestamp, analysis_data, total_coins, trend_coins, range_coins, average_confidence, expires_at)
                VALUES ($1, $2, $3, $4, $5, $6, $7)
            """

            await conn.execute(
                query,
                datetime.now(timezone.utc),
                analysis_data_json,
                total_coins,
                trend_coins,
                range_coins,
                average_confidence,
                expires_at
            )

            logger.info(f"âœ… AI ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {total_coins}ê°œ ì½”ì¸ | ì¶”ì„¸: {trend_coins} | íš¡ë³´: {range_coins}")

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"âŒ AI ì°¨íŠ¸ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise
