"""
ë¦¬ìŠ¤í¬ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ íƒœìŠ¤í¬
"""
import asyncio
import asyncpg
from typing import List, Dict, Any
from datetime import datetime, timedelta, timezone
import json

from src.common.utils.logger import set_logger
from src.scheduler.celery import app as celery_app
from src.app.autotrading_v2.risk_service import RiskAnalysisService

logger = set_logger(__name__)

@celery_app.task(name="scheduler.tasks.risk_analysis.analyze_top_20_risk")
def analyze_top_20_risk():
    """
    ìƒìœ„ 20ê°œ ì½”ì¸ì— ëŒ€í•œ ë¦¬ìŠ¤í¬ ë¶„ì„ (1ì‹œê°„ë§ˆë‹¤)
    """
    try:
        logger.info("ğŸš¨ ë¦¬ìŠ¤í¬ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

        # 1. ìƒìœ„ 20ê°œ ì½”ì¸ ì¡°íšŒ
        top_coins = get_top_20_coins()
        logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ì½”ì¸: {len(top_coins)}ê°œ")

        # 2. ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹¤í–‰
        risk_service = RiskAnalysisService()
        results = []

        for coin in top_coins:
            try:
                # ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    risk_result = loop.run_until_complete(risk_service.analyze_risk(
                        market=coin,
                        analysis_type="daily",
                        days_back=90,
                        personality="conservative",
                        include_analysis=True
                    ))

                    if risk_result and risk_result.get('status') == 'success':
                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                        loop.run_until_complete(save_risk_analysis_to_database(coin, risk_result))
                        results.append({
                            "market": coin,
                            "status": "success",
                            "risk_score": risk_result.get('risk_score', 0),
                            "risk_level": risk_result.get('risk_level', 'UNKNOWN')
                        })
                        logger.info(f"âœ… {coin} ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ")
                    else:
                        logger.warning(f"âš ï¸ {coin} ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹¤íŒ¨")

                finally:
                    loop.close()

            except Exception as e:
                logger.error(f"âŒ {coin} ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                results.append({
                    "market": coin,
                    "status": "error",
                    "error": str(e)
                })

        logger.info(f"ğŸ‰ ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì½”ì¸")
        return {
            "status": "completed",
            "total_markets": len(top_coins),
            "success_count": len([r for r in results if r.get('status') == 'success']),
            "error_count": len([r for r in results if r.get('status') == 'error']),
            "results": results
        }

    except Exception as e:
        logger.error(f"âŒ ë¦¬ìŠ¤í¬ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤íŒ¨: {str(e)}")
        raise

@celery_app.task(name="scheduler.tasks.risk_analysis.analyze_top_20_risk_with_ai")
def analyze_top_20_risk_with_ai():
    """
    ìƒìœ„ 20ê°œ ì½”ì¸ì— ëŒ€í•œ AI ë¦¬ìŠ¤í¬ ë¶„ì„ (1ì‹œê°„ë§ˆë‹¤, ê¸°ì¡´ ë°ì´í„° í™œìš©)
    """
    try:
        logger.info("ğŸ¤– AI ë¦¬ìŠ¤í¬ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

        # 1. ìµœê·¼ ë¦¬ìŠ¤í¬ ë¶„ì„ ë°ì´í„° ì¡°íšŒ (ê¸°ì¡´ ë°ì´í„° í™œìš©)
        risk_data = get_recent_risk_analysis_data()

        if not risk_data:
            logger.warning("âš ï¸ ìµœê·¼ ë¦¬ìŠ¤í¬ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return

        logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ë°ì´í„°: {len(risk_data)}ê°œ")

        # 2. AI ë¶„ì„ìš© ë°ì´í„° êµ¬ì¡° ë³€í™˜
        coins_data = []
        risk_record_ids = []

        for record in risk_data:
            try:
                # ê¸°ì¡´ ë¦¬ìŠ¤í¬ ë¶„ì„ ë°ì´í„°ë¥¼ AI ë¶„ì„ìš©ìœ¼ë¡œ ë³€í™˜
                coin_data = convert_risk_data_for_ai(record)
                coins_data.append(coin_data)
                risk_record_ids.append(record['id'])
                logger.info(f"âœ… {record['asset_symbol']} ë°ì´í„° ë³€í™˜ ì™„ë£Œ")

            except Exception as e:
                logger.error(f"âŒ {record.get('asset_symbol', 'Unknown')} ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {str(e)}")

        # 3. AI ë¶„ì„ ì‹¤í–‰ (ë‹¤ì¤‘ ì½”ì¸)
        if coins_data:
            # ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                from src.app.analysis.ai_service import AIAnalysisService
                ai_service = AIAnalysisService()
                ai_results = loop.run_until_complete(ai_service.analyze_multiple_coins_risk_with_ai(coins_data))

                # 4. ê°€ì¤‘ì¹˜ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘
                weights_snapshot = loop.run_until_complete(ai_service._get_regime_weights())

                # 5. AI ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•© í…Œì´ë¸”ì— ì €ì¥
                loop.run_until_complete(save_ai_analysis_to_database(
                    ai_results=ai_results,
                    chart_record_ids=[],
                    risk_record_ids=risk_record_ids,
                    social_record_ids=[],
                    total_coins=len(coins_data),
                    weights_snapshot=weights_snapshot
                ))
                logger.info(f"ğŸ‰ AI ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ: {len(coins_data)}ê°œ ì½”ì¸")
            finally:
                loop.close()
        else:
            logger.warning("âš ï¸ ë³€í™˜ëœ ë¦¬ìŠ¤í¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

    except Exception as e:
        logger.error(f"âŒ AI ë¦¬ìŠ¤í¬ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤íŒ¨: {str(e)}")
        raise

def get_top_20_coins() -> List[str]:
    """
    ìƒìœ„ 20ê°œ ì½”ì¸ ëª©ë¡ ì¡°íšŒ (ccxt ì‚¬ìš©)
    """
    try:
        import ccxt

        # ë°”ì´ë‚¸ìŠ¤ ê±°ë˜ì†Œ ì´ˆê¸°í™”
        exchange = ccxt.binance({
            'apiKey': '',
            'secret': '',
            'sandbox': False,
            'enableRateLimit': True,
        })

        # 24ì‹œê°„ í†µê³„ ì¡°íšŒ
        tickers = exchange.fetch_tickers()

        # USDT í˜ì–´ë§Œ í•„í„°ë§í•˜ê³  ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        usdt_pairs = []
        for symbol, ticker in tickers.items():
            if symbol.endswith('/USDT') and ticker['quoteVolume'] and float(ticker['quoteVolume']) > 0:
                usdt_pairs.append((symbol, ticker['quoteVolume']))

        # ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 20ê°œ ì„ íƒ
        usdt_pairs.sort(key=lambda x: x[1], reverse=True)
        top_20 = [pair[0] for pair in usdt_pairs[:20]]

        logger.info(f"âœ… ccxtë¥¼ í†µí•œ ìƒìœ„ 20ê°œ ì½”ì¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {len(top_20)}ê°œ")
        logger.info(f"ğŸ“‹ ìƒìœ„ 5ê°œ ì½”ì¸: {', '.join(top_20[:5])}")

        return top_20

    except Exception as e:
        logger.error(f"âŒ ìƒìœ„ 20ê°œ ì½”ì¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        # ê¸°ë³¸ ì½”ì¸ ëª©ë¡ ë°˜í™˜
        return [
            "BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "ADA/USDT",
            "SOL/USDT", "DOGE/USDT", "TRX/USDT", "AVAX/USDT", "LINK/USDT",
            "DOT/USDT", "MATIC/USDT", "LTC/USDT", "BCH/USDT", "UNI/USDT",
            "ATOM/USDT", "FIL/USDT", "XLM/USDT", "VET/USDT", "ICP/USDT"
        ]

def get_recent_risk_analysis_data() -> List[Dict[str, Any]]:
    """
    ìµœê·¼ ë¦¬ìŠ¤í¬ ë¶„ì„ ë°ì´í„° ì¡°íšŒ (AI ë¶„ì„ìš©)
    """
    import asyncio
    import asyncpg
    from src.config.database import database_config

    async def _get_data():
        conn = await asyncpg.connect(
            host=database_config.POSTGRESQL_DB_HOST,
            port=int(database_config.POSTGRESQL_DB_PORT),
            database=database_config.POSTGRESQL_DB_DATABASE,
            user=database_config.POSTGRESQL_DB_USER,
            password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            # ìµœê·¼ 1ì‹œê°„ ë‚´ì˜ ë¦¬ìŠ¤í¬ ë¶„ì„ ë°ì´í„° ì¡°íšŒ
            query = """
                SELECT id, asset_symbol, risk_score, market_risk_level,
                       risk_off_signal, confidence, created_at
                FROM risk_analysis_reports
                WHERE created_at >= NOW() - INTERVAL '1 hour'
                ORDER BY created_at DESC
                LIMIT 20
            """

            rows = await conn.fetch(query)
            return [dict(row) for row in rows]

        finally:
            await conn.close()

    # ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(_get_data())
    finally:
        loop.close()

def convert_risk_data_for_ai(record: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê¸°ì¡´ ë¦¬ìŠ¤í¬ ë¶„ì„ ë°ì´í„°ë¥¼ AI ë¶„ì„ìš©ìœ¼ë¡œ ë³€í™˜
    """
    try:
        # Decimal íƒ€ì…ì„ floatë¡œ ë³€í™˜
        risk_score = record.get('risk_score', 0)
        if hasattr(risk_score, '__float__'):
            risk_score = float(risk_score)

        confidence = record.get('confidence', 0.5)
        if hasattr(confidence, '__float__'):
            confidence = float(confidence)

        return {
            "market": record.get('asset_symbol', 'Unknown'),
            "analysis_type": "daily",
            "days_back": 90,
            "personality": "conservative",
            "risk_score": risk_score,
            "risk_level": record.get('market_risk_level', 'UNKNOWN'),
            "risk_off_signal": record.get('risk_off_signal', False),
            "confidence": confidence
        }
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        return {
            "market": record.get('asset_symbol', 'Unknown'),
            "analysis_type": "daily",
            "days_back": 90,
            "personality": "conservative",
            "risk_score": 0,
            "risk_level": "UNKNOWN",
            "risk_off_signal": False,
            "confidence": 0.5
        }

async def save_risk_analysis_to_database(market: str, risk_result: Dict[str, Any]):
    """
    ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    """
    import asyncpg
    from src.config.database import database_config
    from datetime import datetime, timedelta, timezone

    try:
        conn = await asyncpg.connect(
            host=database_config.POSTGRESQL_DB_HOST,
            port=int(database_config.POSTGRESQL_DB_PORT),
            database=database_config.POSTGRESQL_DB_DATABASE,
            user=database_config.POSTGRESQL_DB_USER,
            password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            # ë§Œë£Œ ì‹œê°„ ì„¤ì • (1ì‹œê°„)
            expires_at = datetime.now(timezone.utc) + timedelta(hours=1)

            query = """
                INSERT INTO risk_analysis_reports
                (asset_symbol, risk_score, market_risk_level, risk_off_signal,
                 confidence, risk_indicators, correlation_analysis, full_analysis_data,
                 created_at, expires_at)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
            """

            await conn.execute(
                query,
                market,
                risk_result.get('risk_score', 0),
                risk_result.get('risk_level', 'UNKNOWN'),
                risk_result.get('risk_off_signal', False),
                risk_result.get('confidence', 0.5),
                json.dumps(risk_result.get('risk_indicators', {})),
                json.dumps(risk_result.get('correlation_analysis', {})),
                json.dumps(risk_result),
                datetime.now(timezone.utc),
                expires_at
            )

            logger.info(f"âœ… ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {market}")

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"âŒ ë¦¬ìŠ¤í¬ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise

async def save_ai_analysis_to_database(
    ai_results: Dict[str, Any],
    chart_record_ids: List[int],
    risk_record_ids: List[int],
    social_record_ids: List[int],
    total_coins: int,
    weights_snapshot: Dict[str, Any] = None
):
    """
    AI ì¢…í•© ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    """
    import asyncpg
    from src.config.database import database_config
    from datetime import datetime, timedelta, timezone
    import json

    try:
        conn = await asyncpg.connect(
                host=database_config.POSTGRESQL_DB_HOST,
                port=int(database_config.POSTGRESQL_DB_PORT),
                database=database_config.POSTGRESQL_DB_DATABASE,
                user=database_config.POSTGRESQL_DB_USER,
                password=database_config.POSTGRESQL_DB_PASSWORD
        )

        try:
            analysis_results = ai_results.get('analysis_results', {})
            summary = ai_results.get('summary', {})

            # ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ êµ¬ì„±
            data_sources = {
                "chart_data": {
                    "source_table": "chart_analysis_reports",
                    "record_ids": chart_record_ids,
                    "total_records": len(chart_record_ids),
                    "timeframe": "minutes:60",
                    "exchange": "binance"
                },
                "risk_data": {
                    "source_table": "risk_analysis_reports",
                    "record_ids": risk_record_ids,
                    "total_records": len(risk_record_ids),
                    "analysis_type": "daily"
                },
                "social_data": {
                    "source_table": "social_analysis_reports",
                    "record_ids": social_record_ids,
                    "total_records": len(social_record_ids),
                    "platforms": ["reddit", "twitter"]
                },
                "weights_snapshot": {
                    "source": "information_service",
                    "api_endpoint": "/api/v2/information/weights/chart",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "description": "AI ë¶„ì„ì— ì‚¬ìš©ëœ ë ˆì§ë³„ ê°€ì¤‘ì¹˜ ìŠ¤ëƒ…ìƒ·",
                    "weights_data": weights_snapshot if weights_snapshot is not None else {}
                }
            }

            # ë§Œë£Œ ì‹œê°„ ì„¤ì • (2ì‹œê°„)
            expires_at = datetime.now(timezone.utc) + timedelta(hours=2)

            query = """
                INSERT INTO ai_analysis_reports
                (analysis_timestamp, chart_analysis, risk_analysis, social_analysis,
                 final_analysis, data_sources, total_coins, expires_at)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
            """

            await conn.execute(
                query,
                datetime.now(timezone.utc),
                json.dumps({}),  # chart_analysis (ë¹ˆ ê°ì²´)
                json.dumps(analysis_results),  # risk_analysis
                json.dumps({}),  # social_analysis (ë¹ˆ ê°ì²´)
                json.dumps({}),  # final_analysis (ë¹ˆ ê°ì²´ - ë³„ë„ ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬)
                json.dumps(data_sources),  # data_sources
                total_coins,
                expires_at
            )

            logger.info(f"âœ… AI ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {total_coins}ê°œ ì½”ì¸")

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"âŒ AI ì¢…í•© ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        raise