"""
ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ V2
- Reddit APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
- X(Twitter) APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
- ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ë° íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚°
"""

import asyncio
import aiohttp
import json
import re
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
import numpy as np
from dataclasses import dataclass

from src.common.utils.logger import set_logger

logger = set_logger("social_data_sources")

# ì†Œì…œë¯¸ë””ì–´ API ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì  ì„¤ì¹˜)
try:
    import praw  # Reddit API
    PRAW_AVAILABLE = True
except ImportError:
    PRAW_AVAILABLE = False
    logger.warning("praw ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. Reddit ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

try:
    import tweepy  # Twitter API
    TWEEPY_AVAILABLE = True
except ImportError:
    TWEEPY_AVAILABLE = False
    logger.warning("tweepy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. Twitter ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

try:
    from textblob import TextBlob  # ì„¼í‹°ë©˜íŠ¸ ë¶„ì„
    TEXTBLOB_AVAILABLE = True
except ImportError:
    TEXTBLOB_AVAILABLE = False
    logger.warning("textblob ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

@dataclass
class RedditPost:
    """Reddit í¬ìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""
    title: str
    content: str
    subreddit: str
    score: int
    upvote_ratio: float
    num_comments: int
    created_utc: datetime
    url: str
    author: str

@dataclass
class TwitterPost:
    """Twitter í¬ìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""
    text: str
    author: str
    retweet_count: int
    like_count: int
    reply_count: int
    created_at: datetime
    tweet_id: str
    is_retweet: bool

@dataclass
class SocialMention:
    """ì†Œì…œë¯¸ë””ì–´ ë©˜ì…˜ ë°ì´í„° í´ë˜ìŠ¤"""
    platform: str
    content: str
    author: str
    engagement_score: float
    sentiment_score: float
    timestamp: datetime
    url: str

class RedditDataCollector:
    """Reddit ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, client_id: str, client_secret: str, user_agent: str):
        """
        Reddit API ì´ˆê¸°í™”
        - Reddit API ì•± ë“±ë¡ í›„ client_id, client_secret í•„ìš”
        - user_agent: "YourApp/1.0 by YourUsername"
        """
        if not PRAW_AVAILABLE:
            logger.error("praw ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. Reddit ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.reddit = None
            return

        try:
            self.reddit = praw.Reddit(
                client_id=client_id,
                client_secret=client_secret,
                user_agent=user_agent
            )
            self.crypto_subreddits = [
                'Bitcoin', 'CryptoCurrency', 'ethereum', 'CryptoMarkets',
                'bitcoinmarkets', 'CryptoMoonShots', 'defi', 'ethtrader',
                'Crypto_com', 'binance', 'Coinbase', 'cryptocurrency'
            ]
            logger.info("âœ… Reddit API ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"Reddit API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.reddit = None

    async def collect_crypto_posts(
        self,
        limit: int = 100,
        time_filter: str = "day"
    ) -> List[RedditPost]:
        """í¬ë¦½í†  ê´€ë ¨ Reddit í¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        try:
            if not self.reddit:
                logger.warning("Reddit APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return []

            posts = []
            total_collected = 0

            for subreddit_name in self.crypto_subreddits:
                if total_collected >= limit:
                    break

                try:
                    subreddit = self.reddit.subreddit(subreddit_name)

                    # Hot í¬ìŠ¤íŠ¸ ìˆ˜ì§‘
                    for submission in subreddit.hot(limit=min(20, limit - total_collected)):
                        if total_collected >= limit:
                            break

                        post = RedditPost(
                            title=submission.title,
                            content=submission.selftext or "",
                            subreddit=subreddit_name,
                            score=submission.score,
                            upvote_ratio=submission.upvote_ratio,
                            num_comments=submission.num_comments,
                            created_utc=datetime.fromtimestamp(submission.created_utc),
                            url=f"https://reddit.com{submission.permalink}",
                            author=str(submission.author) if submission.author else "deleted"
                        )
                        posts.append(post)
                        total_collected += 1

                except Exception as e:
                    logger.warning(f"Subreddit {subreddit_name} ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                    continue

            logger.info(f"âœ… Reddit í¬ìŠ¤íŠ¸ {len(posts)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return posts

        except Exception as e:
            logger.error(f"Reddit ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []

    def calculate_reddit_engagement_score(self, post: RedditPost) -> float:
        """Reddit í¬ìŠ¤íŠ¸ ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° (0 ~ 1)"""
        try:
            # ê¸°ë³¸ ì ìˆ˜: ì—…ë³´íŠ¸ ë¹„ìœ¨
            base_score = post.upvote_ratio

            # ëŒ“ê¸€ ìˆ˜ ê°€ì¤‘ì¹˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
            comment_weight = min(np.log10(post.num_comments + 1) / 3.0, 1.0)

            # ìŠ¤ì½”ì–´ ê°€ì¤‘ì¹˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
            score_weight = min(np.log10(abs(post.score) + 1) / 4.0, 1.0)

            # ìµœì¢… ì°¸ì—¬ë„ ì ìˆ˜
            engagement_score = (base_score * 0.5 + comment_weight * 0.3 + score_weight * 0.2)
            return np.clip(engagement_score, 0.0, 1.0)

        except Exception as e:
            logger.error(f"Reddit ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return 0.0

    def analyze_reddit_sentiment(self, post: RedditPost) -> float:
        """Reddit í¬ìŠ¤íŠ¸ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ (-1 ~ +1)"""
        try:
            # ì œëª©ê³¼ ë‚´ìš© ê²°í•©
            text = f"{post.title} {post.content}".strip()

            if not text:
                return 0.0

            # TextBlobì„ ì‚¬ìš©í•œ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„
            if TEXTBLOB_AVAILABLE:
                blob = TextBlob(text)
                sentiment = blob.sentiment.polarity
            else:
                # TextBlobì´ ì—†ì„ ê²½ìš° ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
                sentiment = self._simple_sentiment_analysis(text)

            # ì—…ë³´íŠ¸ ë¹„ìœ¨ë¡œ ì„¼í‹°ë©˜íŠ¸ ë³´ì •
            upvote_adjustment = (post.upvote_ratio - 0.5) * 0.3

            # ìµœì¢… ì„¼í‹°ë©˜íŠ¸ ì ìˆ˜
            final_sentiment = sentiment + upvote_adjustment
            return np.clip(final_sentiment, -1.0, 1.0)

        except Exception as e:
            logger.error(f"Reddit ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return 0.0

    def _simple_sentiment_analysis(self, text: str) -> float:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„"""
        positive_keywords = ['good', 'great', 'excellent', 'amazing', 'bullish', 'moon', 'pump', 'buy', 'hodl']
        negative_keywords = ['bad', 'terrible', 'awful', 'bearish', 'dump', 'sell', 'crash', 'fear']

        text_lower = text.lower()
        positive_count = sum(1 for word in positive_keywords if word in text_lower)
        negative_count = sum(1 for word in negative_keywords if word in text_lower)

        if positive_count + negative_count == 0:
            return 0.0

        return (positive_count - negative_count) / (positive_count + negative_count)

class TwitterDataCollector:
    """Twitter ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, bearer_token: str):
        """
        Twitter API v2 ì´ˆê¸°í™”
        - Bearer Token í•„ìš” (Academic Research access ê¶Œì¥)
        """
        if not TWEEPY_AVAILABLE:
            logger.error("tweepy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. Twitter ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.client = None
            return

        try:
            self.client = tweepy.Client(bearer_token=bearer_token)
            self.crypto_keywords = [
                'bitcoin', 'btc', 'cryptocurrency', 'crypto', 'ethereum', 'eth',
                'blockchain', 'defi', 'nft', 'web3', 'binance', 'coinbase'
            ]
            logger.info("âœ… Twitter API ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"Twitter API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.client = None

    async def collect_crypto_tweets(
        self,
        max_results: int = 100,
        hours_back: int = 24
    ) -> List[TwitterPost]:
        """í¬ë¦½í†  ê´€ë ¨ íŠ¸ìœ— ìˆ˜ì§‘"""
        try:
            if not self.client:
                logger.warning("Twitter APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return []

            tweets = []
            query = " OR ".join(self.crypto_keywords)

            # ì‹œê°„ í•„í„° (ìµœê·¼ 24ì‹œê°„)
            start_time = datetime.utcnow() - timedelta(hours=hours_back)

            try:
                # Twitter API v2ë¡œ íŠ¸ìœ— ê²€ìƒ‰
                response = self.client.search_recent_tweets(
                    query=query,
                    max_results=min(max_results, 100),  # API ì œí•œ
                    tweet_fields=['created_at', 'public_metrics', 'author_id'],
                    user_fields=['username'],
                    start_time=start_time
                )

                if response.data:
                    for tweet in response.data:
                        # ê³µê°œ ë©”íŠ¸ë¦­ìŠ¤ ì¶”ì¶œ
                        metrics = tweet.public_metrics

                        twitter_post = TwitterPost(
                            text=tweet.text,
                            author=f"@{tweet.author_id}",  # ì‹¤ì œë¡œëŠ” username ë§¤í•‘ í•„ìš”
                            retweet_count=metrics.get('retweet_count', 0),
                            like_count=metrics.get('like_count', 0),
                            reply_count=metrics.get('reply_count', 0),
                            created_at=tweet.created_at,
                            tweet_id=tweet.id,
                            is_retweet=tweet.text.startswith('RT @')
                        )
                        tweets.append(twitter_post)

            except Exception as e:
                logger.warning(f"Twitter API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
                # ëª¨ì˜ ë°ì´í„° ë°˜í™˜
                tweets = self._generate_mock_tweets(max_results)

            logger.info(f"âœ… Twitter íŠ¸ìœ— {len(tweets)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return tweets

        except Exception as e:
            logger.error(f"Twitter ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []

    def _generate_mock_tweets(self, count: int) -> List[TwitterPost]:
        """ëª¨ì˜ íŠ¸ìœ— ë°ì´í„° ìƒì„± (API ì‹¤íŒ¨ ì‹œ)"""
        mock_tweets = []
        base_time = datetime.utcnow()

        mock_texts = [
            "Bitcoin is looking bullish today! ğŸš€",
            "Crypto market is showing strong momentum",
            "Ethereum 2.0 upgrade is game changing",
            "Regulatory concerns are affecting crypto prices",
            "Institutional adoption of Bitcoin continues",
            "DeFi protocols are innovating rapidly",
            "NFT market seems to be cooling down",
            "Crypto volatility is expected this week"
        ]

        for i in range(count):
            text = mock_texts[i % len(mock_texts)]
            mock_tweets.append(TwitterPost(
                text=text,
                author=f"@crypto_user_{i}",
                retweet_count=np.random.randint(0, 100),
                like_count=np.random.randint(0, 500),
                reply_count=np.random.randint(0, 50),
                created_at=base_time - timedelta(hours=i),
                tweet_id=f"mock_{i}",
                is_retweet=False
            ))

        return mock_tweets

    def calculate_twitter_engagement_score(self, tweet: TwitterPost) -> float:
        """Twitter íŠ¸ìœ— ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° (0 ~ 1)"""
        try:
            # ë¦¬íŠ¸ìœ—, ì¢‹ì•„ìš”, ëŒ“ê¸€ ìˆ˜ë¥¼ ì¢…í•©í•œ ì°¸ì—¬ë„ ì ìˆ˜
            total_engagement = tweet.retweet_count + tweet.like_count + tweet.reply_count

            # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™” (0 ~ 1)
            engagement_score = min(np.log10(total_engagement + 1) / 4.0, 1.0)

            return engagement_score

        except Exception as e:
            logger.error(f"Twitter ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return 0.0

    def analyze_twitter_sentiment(self, tweet: TwitterPost) -> float:
        """Twitter íŠ¸ìœ— ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ (-1 ~ +1)"""
        try:
            if not tweet.text:
                return 0.0

            # TextBlobì„ ì‚¬ìš©í•œ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„
            if TEXTBLOB_AVAILABLE:
                blob = TextBlob(tweet.text)
                sentiment = blob.sentiment.polarity
            else:
                # TextBlobì´ ì—†ì„ ê²½ìš° ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
                sentiment = self._simple_sentiment_analysis(tweet.text)

            # ì°¸ì—¬ë„ë¡œ ì„¼í‹°ë©˜íŠ¸ ë³´ì •
            engagement_score = self.calculate_twitter_engagement_score(tweet)
            engagement_adjustment = (engagement_score - 0.5) * 0.2

            # ìµœì¢… ì„¼í‹°ë©˜íŠ¸ ì ìˆ˜
            final_sentiment = sentiment + engagement_adjustment
            return np.clip(final_sentiment, -1.0, 1.0)

        except Exception as e:
            logger.error(f"Twitter ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return 0.0

    def _simple_sentiment_analysis(self, text: str) -> float:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„"""
        positive_keywords = ['good', 'great', 'excellent', 'amazing', 'bullish', 'moon', 'pump', 'buy', 'hodl']
        negative_keywords = ['bad', 'terrible', 'awful', 'bearish', 'dump', 'sell', 'crash', 'fear']

        text_lower = text.lower()
        positive_count = sum(1 for word in positive_keywords if word in text_lower)
        negative_count = sum(1 for word in negative_keywords if word in text_lower)

        if positive_count + negative_count == 0:
            return 0.0

        return (positive_count - negative_count) / (positive_count + negative_count)

class SocialDataAggregator:
    """ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° í†µí•© ë¶„ì„ê¸°"""

    def __init__(self, reddit_config: Optional[Dict[str, str]] = None, twitter_config: Optional[Dict[str, str]] = None):
        """
        ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”

        Args:
            reddit_config: {'client_id': '', 'client_secret': '', 'user_agent': ''}
            twitter_config: {'bearer_token': ''}
        """
        self.reddit_collector = None
        self.twitter_collector = None

        # Reddit ì´ˆê¸°í™”
        if reddit_config and all(k in reddit_config for k in ['client_id', 'client_secret', 'user_agent']):
            self.reddit_collector = RedditDataCollector(
                client_id=reddit_config['client_id'],
                client_secret=reddit_config['client_secret'],
                user_agent=reddit_config['user_agent']
            )

        # Twitter ì´ˆê¸°í™”
        if twitter_config and 'bearer_token' in twitter_config:
            self.twitter_collector = TwitterDataCollector(
                bearer_token=twitter_config['bearer_token']
            )

    async def collect_social_mentions(
        self,
        reddit_limit: int = 50,
        twitter_limit: int = 50,
        hours_back: int = 24
    ) -> List[SocialMention]:
        """ì†Œì…œë¯¸ë””ì–´ ë©˜ì…˜ í†µí•© ìˆ˜ì§‘"""
        try:
            mentions = []

            # Reddit ë°ì´í„° ìˆ˜ì§‘
            if self.reddit_collector:
                try:
                    reddit_posts = await self.reddit_collector.collect_crypto_posts(
                        limit=reddit_limit
                    )

                    for post in reddit_posts:
                        mention = SocialMention(
                            platform="reddit",
                            content=f"{post.title} {post.content}".strip(),
                            author=post.author,
                            engagement_score=self.reddit_collector.calculate_reddit_engagement_score(post),
                            sentiment_score=self.reddit_collector.analyze_reddit_sentiment(post),
                            timestamp=post.created_utc,
                            url=post.url
                        )
                        mentions.append(mention)
                except Exception as e:
                    logger.warning(f"Reddit ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")

            # Twitter ë°ì´í„° ìˆ˜ì§‘
            if self.twitter_collector:
                try:
                    twitter_tweets = await self.twitter_collector.collect_crypto_tweets(
                        max_results=twitter_limit,
                        hours_back=hours_back
                    )

                    for tweet in twitter_tweets:
                        mention = SocialMention(
                            platform="twitter",
                            content=tweet.text,
                            author=tweet.author,
                            engagement_score=self.twitter_collector.calculate_twitter_engagement_score(tweet),
                            sentiment_score=self.twitter_collector.analyze_twitter_sentiment(tweet),
                            timestamp=tweet.created_at,
                            url=f"https://twitter.com/user/status/{tweet.tweet_id}"
                        )
                        mentions.append(mention)
                except Exception as e:
                    logger.warning(f"Twitter ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")

            # API í‚¤ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš° ëª¨ì˜ ë°ì´í„° ìƒì„±
            if not mentions:
                logger.info("API í‚¤ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨, ëª¨ì˜ ì†Œì…œ ë°ì´í„° ìƒì„±")
                mentions = self._generate_mock_social_mentions(reddit_limit, twitter_limit)

            logger.info(f"âœ… ì†Œì…œë¯¸ë””ì–´ ë©˜ì…˜ {len(mentions)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return mentions

        except Exception as e:
            logger.error(f"ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            # ì—ëŸ¬ ì‹œì—ë„ ëª¨ì˜ ë°ì´í„° ë°˜í™˜
            return self._generate_mock_social_mentions(reddit_limit, twitter_limit)

    def _generate_mock_social_mentions(self, reddit_limit: int, twitter_limit: int) -> List[SocialMention]:
        """ëª¨ì˜ ì†Œì…œë¯¸ë””ì–´ ë©˜ì…˜ ë°ì´í„° ìƒì„±"""
        mentions = []
        base_time = datetime.now()

        # Reddit ëª¨ì˜ ë°ì´í„°
        reddit_posts = [
            "Bitcoin is looking bullish today! ğŸš€",
            "Crypto market showing strong momentum",
            "Ethereum 2.0 upgrade is game changing",
            "Regulatory concerns affecting crypto prices",
            "Institutional adoption of Bitcoin continues",
            "DeFi protocols innovating rapidly",
            "NFT market seems to be cooling down",
            "Crypto volatility expected this week"
        ]

        for i in range(min(reddit_limit, len(reddit_posts))):
            content = reddit_posts[i % len(reddit_posts)]
            mentions.append(SocialMention(
                platform="reddit",
                content=content,
                author=f"reddit_user_{i}",
                engagement_score=np.random.uniform(0.3, 0.8),
                sentiment_score=np.random.uniform(-0.5, 0.7),
                timestamp=base_time - timedelta(hours=i),
                url=f"https://reddit.com/r/Bitcoin/comments/mock_{i}"
            ))

        # Twitter ëª¨ì˜ ë°ì´í„°
        twitter_tweets = [
            "Bitcoin breaking resistance levels! ğŸ“ˆ",
            "Crypto market sentiment improving",
            "Ethereum network upgrades showing results",
            "Regulatory clarity needed for crypto",
            "Major banks entering crypto space",
            "DeFi yield farming opportunities",
            "NFT market correction underway",
            "Crypto adoption accelerating globally"
        ]

        for i in range(min(twitter_limit, len(twitter_tweets))):
            content = twitter_tweets[i % len(twitter_tweets)]
            mentions.append(SocialMention(
                platform="twitter",
                content=content,
                author=f"@crypto_trader_{i}",
                engagement_score=np.random.uniform(0.2, 0.9),
                sentiment_score=np.random.uniform(-0.3, 0.6),
                timestamp=base_time - timedelta(hours=i),
                url=f"https://twitter.com/user/status/mock_{i}"
            ))

        return mentions

    def calculate_platform_sentiment(self, mentions: List[SocialMention], platform: str) -> Dict[str, Any]:
        """í”Œë«í¼ë³„ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„"""
        try:
            platform_mentions = [m for m in mentions if m.platform == platform]

            if not platform_mentions:
                return {
                    "platform": platform,
                    "mention_count": 0,
                    "avg_sentiment": 0.0,
                    "avg_engagement": 0.0,
                    "sentiment_score": 0.0,
                    "trend_score": 0.0
                }

            # í‰ê·  ì„¼í‹°ë©˜íŠ¸ ë° ì°¸ì—¬ë„ ê³„ì‚°
            sentiments = [m.sentiment_score for m in platform_mentions]
            engagements = [m.engagement_score for m in platform_mentions]

            avg_sentiment = np.mean(sentiments)
            avg_engagement = np.mean(engagements)

            # ê°€ì¤‘ í‰ê·  (ì°¸ì—¬ë„ ê¸°ë°˜)
            weights = [m.engagement_score for m in platform_mentions]
            weighted_sentiment = np.average(sentiments, weights=weights)

            return {
                "platform": platform,
                "mention_count": len(platform_mentions),
                "avg_sentiment": avg_sentiment,
                "avg_engagement": avg_engagement,
                "sentiment_score": weighted_sentiment,
                "trend_score": avg_engagement
            }

        except Exception as e:
            logger.error(f"{platform} ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                "platform": platform,
                "mention_count": 0,
                "avg_sentiment": 0.0,
                "avg_engagement": 0.0,
                "sentiment_score": 0.0,
                "trend_score": 0.0
            }

    async def analyze_social_sentiment(
        self,
        reddit_limit: int = 50,
        twitter_limit: int = 50,
        hours_back: int = 24
    ) -> Dict[str, Any]:
        """ì†Œì…œë¯¸ë””ì–´ ì„¼í‹°ë©˜íŠ¸ í†µí•© ë¶„ì„"""
        try:
            logger.info("ğŸ” [ì†Œì…œë¯¸ë””ì–´] ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹œì‘")

            # ë°ì´í„° ìˆ˜ì§‘
            mentions = await self.collect_social_mentions(
                reddit_limit=reddit_limit,
                twitter_limit=twitter_limit,
                hours_back=hours_back
            )

            if not mentions:
                return {
                    "overall_sentiment": 0.0,
                    "sentiment_score": 0.0,
                    "trend_score": 0.0,
                    "platform_count": 0,
                    "total_mentions": 0,
                    "platform_analysis": {},
                    "analysis": "ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ì—†ìŒ"
                }

            # í”Œë«í¼ë³„ ë¶„ì„
            platforms = list(set(m.platform for m in mentions))
            platform_analysis = {}

            for platform in platforms:
                platform_analysis[platform] = self.calculate_platform_sentiment(mentions, platform)

            # ì „ì²´ ì„¼í‹°ë©˜íŠ¸ ê³„ì‚° (í”Œë«í¼ë³„ ê°€ì¤‘ì¹˜ ì ìš©)
            platform_weights = {
                'reddit': 0.4,
                'twitter': 0.6
            }

            weighted_sentiment = 0.0
            weighted_trend = 0.0
            total_weight = 0.0
            total_mentions = len(mentions)

            for platform, analysis in platform_analysis.items():
                weight = platform_weights.get(platform, 0.5)
                weighted_sentiment += analysis['sentiment_score'] * weight
                weighted_trend += analysis['trend_score'] * weight
                total_weight += weight

            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            overall_sentiment = weighted_sentiment / total_weight if total_weight > 0 else 0.0
            overall_trend = weighted_trend / total_weight if total_weight > 0 else 0.0

            # ë¶„ì„ ê²°ê³¼
            if overall_sentiment > 0.3:
                analysis = f"ğŸŸ¢ ê¸ì •ì  ì†Œì…œ ì„¼í‹°ë©˜íŠ¸ (íŠ¸ë Œë“œ: {overall_trend:.2f})"
            elif overall_sentiment < -0.3:
                analysis = f"ğŸ”´ ë¶€ì •ì  ì†Œì…œ ì„¼í‹°ë©˜íŠ¸ (íŠ¸ë Œë“œ: {overall_trend:.2f})"
            else:
                analysis = f"ğŸŸ¡ ì¤‘ë¦½ì  ì†Œì…œ ì„¼í‹°ë©˜íŠ¸ (íŠ¸ë Œë“œ: {overall_trend:.2f})"

            logger.info(f"âœ… [ì†Œì…œë¯¸ë””ì–´] ë¶„ì„ ì™„ë£Œ: {analysis}")

            return {
                "overall_sentiment": overall_sentiment,
                "sentiment_score": overall_sentiment,
                "trend_score": overall_trend,
                "platform_count": len(platforms),
                "total_mentions": total_mentions,
                "platform_analysis": platform_analysis,
                "analysis": analysis
            }

        except Exception as e:
            logger.error(f"ì†Œì…œë¯¸ë””ì–´ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                "overall_sentiment": 0.0,
                "sentiment_score": 0.0,
                "trend_score": 0.0,
                "platform_count": 0,
                "total_mentions": 0,
                "platform_analysis": {},
                "analysis": "ì†Œì…œë¯¸ë””ì–´ ë¶„ì„ ì‹¤íŒ¨"
            }
